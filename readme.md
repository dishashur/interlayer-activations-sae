These experiments are inspired by the line of investigations on the utility of intrepretability tools. The Sparse Autoencoders(SAEs) meant to explain the activations of an LLM present some unexplained activations themselves. These experiments are intended to establish the effectiveness of the SAE activations in explaining the interlayer interactions of an LLM.

<!--~ 
the reason behind this being for cases in prompt tuning, it has been observed that most of effect of prompt on the activations begin to show up in the middle ranged layers, not in the beginning, not in the end.
-->

Code base is heavily borrowed from [SAE-Probes](https://github.com/JoshEngels/SAE-Probes) and [SAE-DarkMatter](https://github.com/JoshEngels/SAE-Dark-Matter/) 
